---
title: "DINOv2 - Steps by steps explanations - Picsellia"
description: "Discover DINOv2, an upgrade of DINO. Try using a self-supervised method applied to Vision Transformers. This method enables all-purpose visual features."
date: "2023-11-21"
author:
  name: "Picsellia Team"
category: "Computer Vision"
image: "/images/blog/dinov2-steps-by-steps-explanations-picsellia-hero.png"
published: true
---

The advent of [foundational models](https://crfm.stanford.edu/report.html) ushered in a new era of task-agnostic and cognitive models that adopted [self-supervised learning](https://ai.meta.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/) rather than supervised learning. It has changed the process of developing models. Models have moved from being task-specific to general purpose-based. The initial adoption of foundational models gained a lot of attention around natural language processing (NLP) due to large language models (LLMs) compared to their computer vision (CV) counterparts. However, until DINOv2 models, existing computer vision (CV) foundational models weren't sophisticated enough to be task-agnostic out-of-the-box like LLMs.

This article profoundly examines the underlying techniques and design of DINOv2.

![](/images/blog/dinov2-steps-by-steps-explanations-picsellia-img-0.gif)
