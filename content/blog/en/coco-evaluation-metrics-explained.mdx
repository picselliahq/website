---
title: "COCO Evaluation metrics explained"
description: "Dive into COCO Evaluation Metrics for computer vision, exploring precision, recall, IoU & their meaning. Master object detection with Picsellia."
date: "2023-08-15"
author:
  name: "Picsellia Team"
category: "Computer Vision"
image: "/images/blog/coco-evaluation-metrics-explained-hero.png"
published: true
---

As we saw in a previous article about [Confusion Matrixes](https://www.picsellia.com/post/the-confusion-matrix-in-computer-vision), evaluation metrics are essential for assessing the performance of computer vision models. In this article, we will take a closer look at the COCO Evaluation Metrics and in particular those that can be found on the [Picsellia platform](https://www.picsellia.com/experiment-tracking). 

In order to better understand the following sections, let’s have a quick reminder of some evaluations metrics: 

## Reminders and Definitions

### TP, FP, FN, TN

- **TP as True Positive**: occurs when a model correctly predicts a positive outcome. 
- **TN as True Negative**: occurs when a model correctly predicts a negative outcome.
- **FP as False Positive**: occurs when a model predicts a positive outcome when it should have been negative.
- **FN as False Negative:** occurs when a model predicts a negative outcome when it should have been positive.

### Precision

Precision indicates how many of the predicted positive cases are correct. It quantifies the ratio of true positives to the total number of positive predictions and is computed as follows:

![](/images/blog/coco-evaluation-metrics-explained-img-0.png)
