---
title: "How To Ensure Data Quality – Best Practices"
description: "Data curation is the management of data in an organization such that it is readily available in the present and preserved for future use"
date: "2022-09-18"
author:
  name: "Picsellia Team"
category: "Data Management"
image: "/images/blog/how-to-ensure-data-quality-best-practices-hero.png"
published: true
---

Artificial intelligence (AI) has seen substantial growth in the past decade. Today, AI models are better than ever and have replaced human labor in everyday tasks. However, scientists and engineers have recently started emphasizing the importance of data quality in building high-performance and robust AI models. AI pioneer [Andrew NG](https://en.wikipedia.org/wiki/Andrew_Ng) states:

‍

*“Instead of focusing on the code, companies should focus on developing systematic engineering practices for improving data in ways that are reliable, efficient, and systematic. In other words, companies need to move from a model-centric approach to a data-centric approach.”*

‍

The [data-centric](https://www.picsellia.com/post/data-centric-ai-vs-model) notion of AI brings us to the importance of data curation. **Data curation is the management of data in an organization such that it is readily available in the present and preserved for future use**. Machine learning (ML) models benefit from organized data during training and re-training. Data curation techniques also involve analysis to extract useful features for ML training.

‍

In computer vision (CV), image data is usually available with many data points since, in most cases, it is relatively easy to generate and synthesize. With massive image datasets, curation becomes an integral part of the [CVOps](https://www.picsellia.com/post/creating-a-cvops-platform) pipeline. Let's discuss how data curation aids computer vision tasks.

‍

## Data Curation for Computer Vision

‍

Computer vision engineers spend around 80% of their time curating data. These datasets must be constantly updated to keep up with modern business requirements. Companies must set up proper data [management pipelines](https://www.picsellia.com/automated-pipelines) which allow the acquisition and annotation of data effectively. 

A good dataset contains two main aspects, **quality **and **diversity.** Some of the well-known high-quality image datasets have millions of diverse images. Such as: 

‍

- [MS-COCO](https://cocodataset.org/#home) (328,000 images)
- [Image-Net](https://www.image-net.org/download.php) (1.3 Mil images)
- [Open-Images dataset](https://github.com/openimages/dataset) (~10 Mil images)

‍

Although these are used for benchmarking many state-of-the-art models, the datasets, in their raw form, contain many noisy samples and require a lot of preprocessing and cleaning before performing any tests. It shows how difficult it is to maintain a genuinely perfect dataset.

Creating valuable datasets is always a challenge. It is a recurring process that requires skills and patience. Let's look at some challenges while curating a dataset and understand why many public datasets are unsuitable for modern AI tools.

‍

## Challenges of Data Quality

‍

If you search on [Kaggle](https://www.kaggle.com) or other open data repositories, you will find a plethora of datasets. These datasets are free to use, but their open-source nature raises questions about their credibility. Many of these are uploaded by independent enthusiasts or researchers who put little effort into verifying their correctness and catering to missing values. If used for benchmarking by professionals, these will yield incorrect results, and the tested models will not be reliable.

Creating and maintaining a quality dataset brings a lot of challenges as it requires constant monitoring throughout its lifecycle. Let's discuss these challenges in detail below:

‍

### 1. Ensuring Data Diversity 

Data engineers are required to collect data from multiple sources under various conditions, ensuring diverse data collection. However, this is a tiresome and unexciting task, and proper data collection can take weeks to months. Many modern organizations even spend years collecting relevant data before utilizing it for practical applications.

‍

![](/images/blog/how-to-ensure-data-quality-best-practices-63287777fcaad2e4cbbcc493_data-20diversity.png)
